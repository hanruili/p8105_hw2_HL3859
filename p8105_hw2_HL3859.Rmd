---
title: "p8105_hw2_HL3859"
author: "Hanrui Li"
date: "2024-09-25"
output: github_document
---

# Problem 1

```{r}
library(tidyverse)

nyc = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |>
  janitor::clean_names()

nyc_clean = 
  nyc |>
  select(line, station_name, station_latitude, station_longitude, route1:route11, 
         entry, vending, entrance_type, ada) |>
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

nyc_clean
```

The dataset contains `line` which shows 36 subway lines. `station_name` represents the names of the station. `station_latitude` and `station_longitude` represent the coordinates of the station. `route1` to `route11` show the subway routes served by the station, there are 11 routes. `entry` indicates whether entrance is allowed (TRUE/FALSE). `vending` indicates whether there is a vending machine (YES/NO). `entrance_type` is the type of entrance (e.g. `r unique(nyc_clean$entrance_type)`). `ada` inndicates whether the station is compliant with ADA standards (TRUE/FALSE). I selected relevant columns from the dataset and converted the `entry` variable to a logical variable for easier analysis. After cleaning, the dataset has `r nrow(nyc_clean)` rows and `r ncol(nyc_clean)` columns. This dataset is tidy as each column represents a variable and each row represents a single observation (an entrance/exit).

```{r}
nyc_clean |>
  distinct(line, station_name) |>
  nrow()
```

- There are 465 distinct stations.

```{r}
nyc_clean |>
  filter(ada == "TRUE") |>
  distinct(line, station_name) |>
  nrow()
```

- 84 stations are ADA compliant.

```{r}
nyc_clean |>
  filter(vending == "NO") |>
  summarise(proportion = mean(entry))
```

- 37.70% of station entrances / exits without vending allow entrance.

```{r}
nyc_routes = 
  nyc_clean |>
  mutate(across(starts_with("route"), as.character)) |>
  pivot_longer(
    route1:route11,
    names_to = "route_name", 
    values_to = "route_number") |>
  filter(!is.na(route_number))

nyc_routes

nyc_routes |>
  filter(route_number == "A") |>
  distinct(line, station_name) |>
  nrow()

nyc_routes |>
  filter(route_number == "A", ada == "TRUE") |>
  distinct(line, station_name) |>
  nrow()
```

- There are 60 distinct stations serve the A train.

- Of the stations that serve the A train, 17 are ADA compliant.


# Problem 2

```{r}
library(readxl)
library(dplyr)

trash_wheel = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1) |>
  select(dumpster = `Dumpster`, month = `Month`, year = `Year`, date = `Date`,
      weight_tons = `Weight (tons)`, volume_cubic_yards = `Volume (cubic yards)`,
      plastic_bottles = `Plastic Bottles`, polystyrene = `Polystyrene`,
      cigarette_butts = `Cigarette Butts`, glass_bottles = `Glass Bottles`,
      plastic_bags = `Plastic Bags`, wrappers = `Wrappers`,
      sports_balls = `Sports Balls`, homes_powered = `Homes Powered*`) |>
  filter(!is.na(dumpster)) |>
  mutate(sports_balls = as.integer(round(sports_balls)), 
         homes_powered = (weight_tons * 500 / 30),
         trash_wheel = "Mr. Trash Wheel")

trash_wheel
```

```{r}
prof_trash_wheel = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1) |>
  select(dumpster = `Dumpster`, month = `Month`, year = `Year`, date = `Date`,
      weight_tons = `Weight (tons)`, volume_cubic_yards = `Volume (cubic yards)`,
      plastic_bottles = `Plastic Bottles`, polystyrene = `Polystyrene`,
      cigarette_butts = `Cigarette Butts`, glass_bottles = `Glass Bottles`,
      plastic_bags = `Plastic Bags`, wrappers = `Wrappers`,
      homes_powered = `Homes Powered*`) |>
  filter(!is.na(dumpster)) |>
  mutate(year = as.character(year))
  
prof_trash_wheel

gwynnda_trash_wheel = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1) |>
  select(dumpster = `Dumpster`, month = `Month`, year = `Year`, date = `Date`,
      weight_tons = `Weight (tons)`, volume_cubic_yards = `Volume (cubic yards)`,
      plastic_bottles = `Plastic Bottles`, polystyrene = `Polystyrene`,
      cigarette_butts = `Cigarette Butts`, plastic_bags = `Plastic Bags`, 
      wrappers = `Wrappers`, homes_powered = `Homes Powered*`) |>
  filter(!is.na(dumpster)) |>
  mutate(year = as.character(year))

gwynnda_trash_wheel
```

```{r}
combine = 
  bind_rows(trash_wheel, prof_trash_wheel, gwynnda_trash_wheel)

combine
```

The combined dataset from the Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda trash wheels includes a total of `r nrow(combine)` observations, each representing a dumpster filled with trash removed from Baltimore's Inner Harbor. Key variables include the date (`date`, e.g. `r combine$date[1]`), the weight of trash collected (`weight_tons)`, e.g. `r combine$weight_tons[1]` tons), and the number of sports balls recovered (`sports_balls`, e.g. `r combine$sports_balls[1]`). Additionally, the dataset tracks the number of cigarette butts collected (`cigarette_butts`, e.g. `r combine$cigarette_butts[1]`). 

For Professor Trash Wheel, the total weight of trash collected across all available records is `r prof_trash_wheel |> summarize(total_weight = sum(weight_tons, na.rm = TRUE)) |> pull(total_weight)` tons. 

In June 2022, Gwynnda collected a total of `r gwynnda_trash_wheel |> filter(format(date, "%Y-%m") == "2022-06") |> summarize(total_butts = sum(cigarette_butts, na.rm = TRUE)) |> pull(total_butts)` cigarette butts.


# Problem 3

```{r}
library(tidyverse)

bakers <- read_csv("data/gbb_datasets/bakers.csv")
bakes <- read_csv("data/gbb_datasets/bakes.csv")
results <- read_csv("data/gbb_datasets/results.csv", skip = 2)
viewers <- read_csv("data/gbb_datasets/viewers.csv")


bakers <- bakers |>
  mutate(Series = as.numeric(Series), `Baker Age` = as.numeric(`Baker Age`))

merged_data <- bakes |>
  left_join(bakers, by = c("Baker" = "Baker Name", "Series" = "Series")) |>
  left_join(results, by = c("Baker" = "baker", "Series" = "series", "Episode" = "episode"))

missing_data <- merged_data |>
  summarise_all(~ sum(is.na(.)))

final_data <- merged_data %>%
  arrange(Series, Episode, Baker)

write_csv(final_data, "data/gbb_datasets/final_data.csv")


```













